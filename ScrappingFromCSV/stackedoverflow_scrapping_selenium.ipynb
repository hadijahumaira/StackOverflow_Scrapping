{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def clean_text(text):\n",
    "    return ' '.join(text.split())  # Menghapus newline dan menggabungkan teks menjadi satu baris\n",
    "\n",
    "# Inisialisasi driver Chrome\n",
    "driver = webdriver.Chrome()\n",
    "driver.set_window_size(1300, 800)\n",
    "\n",
    "# Baca file CSV yang sudah ada\n",
    "file_path = 'HasilCrawl.csv'\n",
    "df_links = pd.read_csv(file_path)\n",
    "\n",
    "questions_data = []\n",
    "\n",
    "# Langkah 1: Buka halaman utama Stack Overflow\n",
    "driver.get(\"https://stackoverflow.com/\")\n",
    "\n",
    "# Langkah 2: Klik pada link \"Tags\"\n",
    "tags_link = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.LINK_TEXT, \"Tags\"))\n",
    ")\n",
    "tags_link.click()\n",
    "\n",
    "# Langkah 3: Klik pada tag \"Python\"\n",
    "python_tag_link = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.LINK_TEXT, \"Python\"))\n",
    ")\n",
    "python_tag_link.click()\n",
    "\n",
    "# Langkah 4: Crawling pertanyaan dari halaman tag Python\n",
    "content = driver.page_source\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "# Ekstrak pertanyaan dari ringkasan\n",
    "for area in soup.find_all('div', class_=\"s-post-summary js-post-summary\"):\n",
    "    title = area.find('a', class_=\"s-link\").get_text(strip=True)  # Judul pertanyaan\n",
    "    question_excerpt = clean_text(area.find('div', class_=\"s-post-summary--content-excerpt\").get_text(strip=True))  # Ringkasan pertanyaan\n",
    "    votes = area.select_one('.s-post-summary--stats-item__emphasized .s-post-summary--stats-item-number').get_text(strip=True)  # Jumlah vote\n",
    "    answers = area.select_one('.s-post-summary--stats-item:nth-child(2) .s-post-summary--stats-item-number').get_text(strip=True)  # Jumlah jawaban\n",
    "    views = area.select_one('.s-post-summary--stats-item:nth-child(3) .s-post-summary--stats-item-number').get_text(strip=True)  # Jumlah tampilan\n",
    "    tags = [tag.get_text(strip=True) for tag in area.select('.s-post-summary--meta-tags .post-tag')]  # Tag pertanyaan\n",
    "    author = area.select_one('.s-user-card--info .flex--item').get_text(strip=True) if area.select_one('.s-user-card--info .flex--item') else 'Anonymous'  # Penulis\n",
    "    reputation = area.select_one('.s-user-card--rep').get_text(strip=True) if area.select_one('.s-user-card--rep') else '0'  # Reputasi\n",
    "    link = \"https://stackoverflow.com\" + area.find('a', class_=\"s-link\")['href']  # Link pertanyaan\n",
    "\n",
    "    # Simpan data ke dalam dictionary\n",
    "    question_info = {\n",
    "        'Title': title,\n",
    "        'Excerpt': question_excerpt,\n",
    "        'Votes': votes,\n",
    "        'Answers': answers,\n",
    "        'Views': views,\n",
    "        'Tags': ', '.join(tags),\n",
    "        'Author': author,\n",
    "        'Reputation': reputation,\n",
    "        'Link': link\n",
    "    }\n",
    "\n",
    "    questions_data.append(question_info)\n",
    "\n",
    "# Setelah mengambil data ringkasan, sekarang ambil detail dari setiap pertanyaan yang ada di df_links\n",
    "for index, row in df_links.iterrows():\n",
    "    link = row['Link_question']  # Mengambil link pertanyaan dari DataFrame\n",
    "    driver.get(link)  # Kunjungi link pertanyaan\n",
    "    question_content = driver.page_source\n",
    "    question_soup = BeautifulSoup(question_content, 'html.parser')\n",
    "\n",
    "    # Ambil detail pertanyaan\n",
    "    question_text = clean_text(question_soup.find('div', class_=\"s-prose js-post-body\").text)  # Isi teks pertanyaan\n",
    "    # Cari pertanyaan yang sesuai dengan link dan tambahkan detail teks\n",
    "    for question in questions_data:\n",
    "        if question['Link'] == link:\n",
    "            question['Question_Text'] = question_text  # Menyimpan isi pertanyaan ke dalam dictionary\n",
    "            break\n",
    "\n",
    "# Tutup driver setelah selesai\n",
    "driver.quit()\n",
    "\n",
    "# Simpan DataFrame ke file CSV\n",
    "output_file = 'HasilScrappingDenganCSV_Selenium.csv'\n",
    "df_questions = pd.DataFrame(questions_data)\n",
    "df_questions.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
